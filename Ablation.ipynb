{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/golo/miniconda3/envs/echolga_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from src.hypergraphs import HeterogeneousHyperGraph\n",
    "from src.components import FiveWOneH\n",
    "from src import components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Headlines'\n",
    "df = pd.read_csv('./datasets/' + dataset  + '.csv')\n",
    "threew = FiveWOneH(dataset, df, 0.2)\n",
    "dic_who_headlines = threew.generate_dict('Who')\n",
    "dic_where_headlines = threew.generate_dict('Where')\n",
    "dic_when, dic_where, dic_who = components.dic_when_headlines, dic_where_headlines, dic_who_headlines\n",
    "num_node_types = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Risk'\n",
    "dic_when, dic_where, dic_who = components.dic_when_risk, components.dic_where_risk, components.dic_who_risk\n",
    "num_node_types = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'FinCausal'\n",
    "dic_when, dic_where, dic_who = components.dic_when_fincausal, components.dic_where_fincausal, components.dic_who_fincausal\n",
    "num_node_types = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Twitter'\n",
    "df = pd.read_csv('./datasets/' + dataset  + '.csv')\n",
    "threew = FiveWOneH(dataset, df, 0.2)\n",
    "dic_who_twitter = threew.generate_dict('Who')\n",
    "dic_when, dic_where, dic_who = components.dic_when_twitter, components.dic_where_twitter, dic_who_twitter\n",
    "num_node_types = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "df = pd.read_csv('./datasets/' + dataset + '.csv')\n",
    "het_hyperG = HeterogeneousHyperGraph(' Cause', ' Effect', df, m, dic_who, dic_when, dic_where, dataset)\n",
    "het_hyperG.add_main_edges()\n",
    "het_hyperG.add_main_node_labels()\n",
    "het_hyperG.add_main_node_embeddings()\n",
    "het_hyperG.add_secundary_edges()\n",
    "het_hyperG.add_secundary_node_labels()\n",
    "het_hyperG.add_secundary_node_embeddings()\n",
    "graphs_kfold = het_hyperG.generate_kfold_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eCHOLGA import HeterogeneousGNNModel\n",
    "from src.eCHOLGA import one_class_loss\n",
    "from src.utils import plot_confusion_matrix\n",
    "import torch\n",
    "from torch import nn\n",
    "import random\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def run(ep,ra,of,rf,nt,ofi,rfi,nti):\n",
    "    scenarios = ['1', '2', '3']\n",
    "    for scenario in scenarios:\n",
    "        np.random.seed(42)\n",
    "        torch.manual_seed(42)\n",
    "        random.seed(42)\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "        l_f1 = []\n",
    "        fold = 0\n",
    "        for g_obs in graphs_kfold:\n",
    "            #het_hyperG.add_relation_edges_pseudo_labels(4, g_obs, llm_pseudo_label, system_prompt, user_prompt)\n",
    "            epochs, radius, lr, dim = ep, ra, 0.008, 3\n",
    "            heterogeneous_model = HeterogeneousGNNModel('cuda:0', lr, radius, dim, num_node_types, g_obs, 384)\n",
    "            embeddings, loss_node_type, loss_recon, loss_recon_u, loss_ocl, embeddings_relation,f1s = [], [], [], [], [], [], []\n",
    "            node_type_labels = [g_obs.nodes[node]['node_type'] for node in g_obs.nodes()]\n",
    "\n",
    "            index = 0\n",
    "            node_to_index = {}\n",
    "            for node in g_obs.nodes():\n",
    "                node_to_index[node] = index\n",
    "                index+=1\n",
    "\n",
    "            ocl_factor = 0\n",
    "            rec_factor = 0\n",
    "            nt_factor = 1\n",
    "\n",
    "            for epoch in range(epochs):\n",
    "                heterogeneous_model.get_gnn_model().train()\n",
    "                heterogeneous_model.get_optimizer().zero_grad()\n",
    "\n",
    "                node_representation, pred_node_type = heterogeneous_model.get_gnn_model().encode(heterogeneous_model.get_graph_torch().embedding.float(), heterogeneous_model.get_graph_torch().edge_index)\n",
    "\n",
    "                loss1 = one_class_loss(heterogeneous_model.get_center(), heterogeneous_model.get_radius(), node_representation, heterogeneous_model.get_mask())\n",
    "                loss2 = heterogeneous_model.get_gnn_model().recon_loss(node_representation, heterogeneous_model.get_graph_torch().edge_index)\n",
    "                loss3 = nn.CrossEntropyLoss()(pred_node_type, torch.Tensor(node_type_labels).squeeze().long().to('cuda:0'))\n",
    "\n",
    "                loss = loss1 * min(of, ocl_factor) \n",
    "                \n",
    "                if scenario == '2' or scenario == '3':\n",
    "                    loss+= loss2 * min(rf, rec_factor)\n",
    "                \n",
    "                if scenario == '3':\n",
    "                    loss+= loss3 * max(nt, nt_factor) \n",
    "\n",
    "                loss.backward()\n",
    "                heterogeneous_model.get_optimizer().step()\n",
    "                embeddings.append(node_representation)\n",
    "                if epoch%100 == 0:\n",
    "                    ocl_factor = ocl_factor + ofi\n",
    "                    rec_factor = rec_factor + rfi\n",
    "                    nt_factor = max(0,(nt_factor - nti)) \n",
    "                    #f1 = heterogeneous_model.one_class_homogeneousGNN_prediction(node_representation, node_to_index, True)['macro avg']['f1-score']   \n",
    "                    #print(f'Ep {int(epoch)} | Ocl: {loss1.detach().cpu().numpy():.3f} | Rec: {loss2.detach().cpu().numpy():.3f} | NT: {loss3.detach().cpu().numpy():.3f} | F1: {f1*100:.2f}%')\n",
    "\n",
    "            y_true, y_pred = heterogeneous_model.one_class_homogeneousGNN_prediction(node_representation, node_to_index, False)\n",
    "            l_f1.append(heterogeneous_model.one_class_homogeneousGNN_prediction(node_representation, node_to_index, True)['macro avg']['f1-score'])\n",
    "            #print(f'F1-macro: {l_f1[fold]}')\n",
    "            fold+=1\n",
    "            #plot_confusion_matrix(y_true, y_pred)\n",
    "            #print(classification_report(y_true, y_pred))\n",
    "\n",
    "        f1_macro_mean = np.mean(l_f1)\n",
    "        f1_macro_std = np.std(l_f1)\n",
    "        print(scenario, dataset, f1_macro_mean, f1_macro_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Headlines 0.26458418783990195 0.0004885520090794726\n",
      "2 Headlines 0.26458418783990195 0.0004885520090794726\n",
      "3 Headlines 0.5722717342165249 0.012336220890890794\n"
     ]
    }
   ],
   "source": [
    "run(6000, 0.4, 0.5, 0, 0.5, 0.02, 0, 0.02) # HEADLINES 0.5 0 0.5 = 0.02 em 0.02 nos dois - 6k epoca - r  0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 FinCausal 0.3125 0.0\n",
      "2 FinCausal 0.3942045271150213 0.025607677736310976\n",
      "3 FinCausal 0.4149257372459383 0.027879923249676454\n"
     ]
    }
   ],
   "source": [
    "run(6000, 0.5, 0.7, 0.2, 0.1, 0.04, 0.01, 0.04) # FINCAUSAL 0.7 0.2 0.1 = 0.04 em 0.04 nos dois - 6k epoca - r  0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Risk 0.32365579263350763 0.0011969437133096572\n",
      "2 Risk 0.6572955932290797 0.04400006338909593\n",
      "3 Risk 0.6191197601273872 0.13757701735184158\n"
     ]
    }
   ],
   "source": [
    "run(6000, 0.3, 0.6, 0.3, 0.1, 0.02, 0.01, 0.02) # RISK 0.6 0.3 0.1 = 0.02 em 0.02 nos dois - 6k epoca - r  0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Twitter 0.3338226249909558 0.000981975283743149\n",
      "2 Twitter 0.4961669877880996 0.03163076679804815\n",
      "3 Twitter 0.4882791044707675 0.032050628005783136\n"
     ]
    }
   ],
   "source": [
    "run(3000, 0.4, 0.8, 0.15, 0.05, 0.05, 0.01, 0.05) # Twitter 0.8 0.15 0.05 = 0.05 em 0.05 nos dois - 3k epoca - r  0.4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "echolga_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
