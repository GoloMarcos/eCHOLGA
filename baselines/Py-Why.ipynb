{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d49fa3c1-d23d-4bf8-8e8a-f2c61c5c9da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "system_prompt = \"\"\"You are an AI for causal reasoning designed to detect causality between events. Your task is to classify the event one causes the event two, returnin a structured JSON format with the class \"causal\" or \"non_causal\". The class needs to be the strings \"causal\" or \"non_causal\".\n",
    "\n",
    "Your output should be formatted as a JSON object. Below is an example of the expected output structure:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"class\": \"causal\"\n",
    "}\n",
    "```\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "\"Please read the following event text pairs and detect causality between the events. Your response should be the class representing if the event one causes the event two, in the form of a JSON, in which, the class can be \"causal\" or \"non_causal\", with the following structure:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"class\": \"non_causal\"\n",
    "}\n",
    "```\n",
    "\n",
    "Important: Your output must be in JSON format only. No additional text, explanations, or comments are allowed. Do not include any other information outside of the JSON structure.\n",
    "\n",
    "Now, apply the same logic to the following event pairs.\n",
    "\n",
    "### Event pairs to analyze:\n",
    "Event one: {cause}\n",
    "Event two: {effect}\n",
    "\"\"\"\n",
    "\n",
    "def isCauseEffect(model, system_prompt, user_prompt):\n",
    "  response: ChatResponse = chat(model=model, messages=[\n",
    "    {\n",
    "      'role': 'system',\n",
    "      'content': system_prompt,\n",
    "    },\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': user_prompt,\n",
    "    },],options= {\n",
    "                  'temperature': 0,\n",
    "                  'num_ctx': 10240,\n",
    "                  'seed': 81\n",
    "                  }\n",
    "                                )\n",
    "  return response['message']['content'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32154ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': 'causal'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "r = isCauseEffect('phi3:14b',system_prompt,user_prompt.replace('{cause}','New York Democrats cancel 2020 primary, kicking Bernie Sanders off the ballot').replace('{effect}','Bernie Sanders campaign says New York should lose its delegates after cancellation of presidential primary'))\n",
    "r = r.replace('```json', '')\n",
    "r = r.replace('```', '')\n",
    "json_obj = json.loads(r)\n",
    "json_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3284df80-1d75-4687-8325-ebf28afc09bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "datasets = ['FinCausal', 'Risk', 'Headlines', 'Twitter'] \n",
    "\n",
    "for model in ['llama3:8b', 'llama3:70b', 'phi3:14b', 'gemma2:27b', 'qwen2:7b']:\n",
    "    print(model)\n",
    "    for dataset in datasets:\n",
    "        print(dataset)\n",
    "        df = pd.read_csv('./datasets/' + dataset + '.csv') \n",
    "        for index, row in df.iterrows():\n",
    "            if (dataset == 'Headlines' and (index == 450 or index == 1737 or index == 1870 or index == 2198 or index == 2322)) or (dataset == 'Twitter' and (index == 34 or index == 173 or index == 322 or index == 425 or index == 657 or index == 758 or index == 773)): continue\n",
    "            while True:\n",
    "                r = isCauseEffect(model,system_prompt,user_prompt.replace('{cause}',str(row[' Cause'])).replace('{effect}',str(row[' Effect'])))\n",
    "                r = r.replace('```json', '')\n",
    "                r = r.replace('```', '')\n",
    "                try:\n",
    "                    json_obj = json.loads(r)\n",
    "                    if json_obj['class'] == 'causal' or json_obj['class'] == 'non_causal':\n",
    "                        df.at[index,'llm_class'] = json_obj['class']\n",
    "                        break\n",
    "                    else:\n",
    "                        print(row[' Cause'])\n",
    "                        print(row[' Effect'])\n",
    "                        print(index,r)\n",
    "                except:\n",
    "                    print(r)\n",
    "        df.to_csv('results/' + dataset + '_' + model + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86cf39a0-d07d-458e-8d7f-e348647e2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "def generate_homogeneous_graph(df, model, llm_class = False, cause_col = ' Cause', effect_col = ' Effect'):\n",
    "   \n",
    "   graph = nx.DiGraph()\n",
    "   df[cause_col] = df[cause_col].astype(str)\n",
    "   df[effect_col] = df[effect_col].astype(str)\n",
    "\n",
    "   df['Embedding_' + cause_col] = list(model.encode(df[cause_col]))\n",
    "   df['Embedding_' + effect_col] = list(model.encode(df[effect_col]))\n",
    "\n",
    "   for _, row in df.iterrows():\n",
    "      cause = row[cause_col]\n",
    "      effect = row[effect_col]\n",
    "      \n",
    "      graph.add_edge('event:' + cause, 'relation: ' + cause + '_' + effect)\n",
    "      graph.add_edge('relation: ' + cause + '_' + effect, 'event:' + effect)\n",
    "      \n",
    "      graph.nodes['event:' + cause]['label'] = 'aux'\n",
    "      graph.nodes['event:' + effect]['label'] = 'aux'\n",
    "      graph.nodes['relation: ' + cause + '_' + effect]['label'] = row['Label']\n",
    "      if llm_class:\n",
    "        graph.nodes['event:' + cause]['llm_label'] = 'aux'\n",
    "        graph.nodes['event:' + effect]['llm_label'] = 'aux'\n",
    "        graph.nodes['relation: ' + cause + '_' + effect]['llm_label'] = row['llm_class']\n",
    "\n",
    "      graph.nodes['event:' + cause]['embedding'] = np.asarray(row['Embedding_' + cause_col], dtype=np.float64)\n",
    "      graph.nodes['event:' + effect]['embedding'] = np.asarray(row['Embedding_' + effect_col], dtype=np.float64)\n",
    "      graph.nodes['relation: ' + cause + '_' + effect]['embedding'] = np.mean([np.asarray(row['Embedding_' + cause_col], dtype=np.float64),np.asarray(row['Embedding_' + effect_col], dtype=np.float64)], axis=0)\n",
    "\n",
    "   return graph\n",
    "              \n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['causal', 'non_causal'])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "\n",
    "def fold_analysis(graph):\n",
    "    df_egae = pd.DataFrame()\n",
    "\n",
    "    df_egae['y'] = [graph.nodes[node]['label'] for node in graph.nodes()]\n",
    "    df_egae['x'] = [node for node in graph.nodes()]\n",
    "    df_egae['y_llm'] = [graph.nodes[node]['llm_label'] for node in graph.nodes()]\n",
    "\n",
    "    df = df_egae[df_egae['y'] != 'aux'].reset_index(drop=True)\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    y_trues, y_preds = [], []\n",
    "    for _, test_index in kf.split(df['x'], df['y']):\n",
    "\n",
    "        y_true = df[df.index.isin(test_index)]['y'].to_list()\n",
    "        \n",
    "        y_pred = df[df.index.isin(test_index)]['y_llm'].to_list()\n",
    "\n",
    "        #f1_macro = classification_report(y_true, y_pred, output_dict=True)['macro avg']['f1-score']\n",
    "\n",
    "        y_trues = np.concatenate([y_trues,y_true])\n",
    "        y_preds = np.concatenate([y_preds,y_pred])\n",
    "\n",
    "    #plot_confusion_matrix(y_trues, y_preds)\n",
    "\n",
    "    return round(classification_report(y_trues, y_preds, output_dict=True)['macro avg']['f1-score'], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90ab72ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3:8b\n",
      "0.727 & 0.57 & 0.61 & 0.761 & \n",
      "\n",
      "phi3:14b\n",
      "0.659 & 0.509 & 0.626 & 0.695 & \n",
      "\n",
      "gemma2:27b\n",
      "0.72 & 0.63 & 0.734 & 0.822 & \n",
      "\n",
      "qwen2:7b\n",
      "0.691 & 0.472 & 0.654 & 0.719 & \n",
      "\n",
      "llama3:70b\n",
      "0.726 & 0.623 & 0.728 & 0.767 & \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pickle as pkl\n",
    "\n",
    "m = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "for model in ['llama3:8b', 'phi3:14b', 'gemma2:27b', 'qwen2:7b', 'llama3:70b']:\n",
    "    print(model)\n",
    "    for dataset in ['Risk', 'Twitter', 'Headlines', 'FinCausal']:\n",
    "        df = pd.read_csv('results/' + dataset + '_' + model + '.csv') \n",
    "        df = df.dropna().reset_index(drop=True)\n",
    "        graph = generate_homogeneous_graph(df, m, llm_class=True)\n",
    "        f1_macro = fold_analysis(graph)\n",
    "        print(round(f1_macro, 3), end=\" & \")\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "echolgat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
